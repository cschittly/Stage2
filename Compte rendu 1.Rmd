---
title: "Etude dimension"
author: "Camille Schittly"
date: "2024-04-11"
output:
  pdf_document: default
  html_document: default
---

# Ranger données

```{r}
library(readxl)
library(dplyr)
library(tidyverse)
questionnaire <- read_excel("~/stage/Stage/questionnaire.xlsx")
head(questionnaire)

QPE4PL = questionnaire %>% select(-Individu, -Lycée, -Classe, -Sexe, -APSA)
QPE4PL=na.omit(QPE4PL)
QPE4PLlesson =QPE4PL %>% select(1:23)
QPE4PLimpact = QPE4PL %>% select(24:50)


```

```{r}
length(questionnaire$Individu)
sum(is.na(QPE4PL)) #à faire avant le na.omit
sum(!is.na(QPE4PL)) # à faire avant la na.omit
```


Il y a 493 personne qui on répondu à ce questionnaire.

Sur l'ensemble des réponses (24491) il y en a 159 qui n'ont pas répondu


# Nombre de participant, statistique descriptive

On peut regarder les nombre de participant par genre et classe

```{r}

# Charger les packages
library(ggplot2)
library(nortest)
library(ggpubr)
library(tidyverse)

# Exemple de données : DataFrame avec réponses de 5 questions
set.seed(123)
responses <- data.frame(
  Q1 = questionnaire$Q1,
  Q2 = questionnaire$Q2,
  Q3 = questionnaire$Q3,
  Q4 = questionnaire$Q4,
  Q5 = questionnaire$Q5
)

# Fonction pour analyser la normalité de chaque question
analyze_normality <- function(data) {
  results <- list()
  for (col in colnames(data)) {
    question_data <- data[[col]]
    
    # Histogramme
    p1 <- ggplot(data.frame(question_data), aes(x = question_data)) +
      geom_histogram(aes(y = ..density..), bins = 5, fill = "blue", alpha = 0.7) +
      geom_density(color = "red", size = 1) +
      ggtitle(paste("Histogramme des réponses pour", col)) +
      xlab("Réponses") +
      ylab("Densité")
    
    # Q-Q Plot
    p2 <- ggqqplot(data.frame(question_data), x = "question_data", title = paste("Q-Q Plot des réponses pour", col))
    
    # Boxplot
    p3 <- ggplot(data.frame(question_data), aes(y = question_data)) +
      geom_boxplot(fill = "blue", alpha = 0.7) +
      ggtitle(paste("Boxplot des réponses pour", col)) +
      ylab("Réponses")
    
    # Tests statistiques
    shapiro_test <- shapiro.test(question_data)
    ks_test <- lillie.test(question_data)
    ad_test <- ad.test(question_data)
    
    results[[col]] <- list(
      plots = list(histogram = p1, qqplot = p2, boxplot = p3),
      tests = list(shapiro = shapiro_test, ks = ks_test, ad = ad_test)
    )
  }
  return(results)
}

# Analyser la normalité pour chaque question
normality_results <- analyze_normality(responses)

qqnorm(questionnaire$Q3, main = "QQ Plot des Scores d'Impact")
qqline(questionnaire$Q3, col = "red")
qqnorm(questionnaire$Q4, main = "QQ Plot des Scores d'Impact")
qqline(questionnaire$Q4, col = "red")
qqnorm(questionnaire$Q40, main = "QQ Plot des Scores d'Impact")
qqline(questionnaire$Q40, col = "red")
library(ggplot2)


qq_plot_impact <- ggplot(questionnaire, aes(sample = Q1)) +
  stat_qq_band() +
  stat_qq_line() +
  stat_qq_point() +
  ggtitle("QQ Plot des Scores d'Impact avec Intervalle de Confiance") +
  theme_minimal()

```


```{r}

library(dplyr)
grouped_data <- questionnaire %>%
  group_by(Sexe, Classe) %>%
  summarise(Nombre_de_participants = n())

# Affichage des résultats
print(grouped_data)

grouped_dataS <- questionnaire %>%
  group_by(Sexe) %>%
  summarise(Nombre_de_participants = n())
library(lattice)

# Affichage des résultats
print(grouped_dataS)
```

Bizarre car H = M je pense dans D42 du excel


# Outlier

Un outlier, ou valeur aberrante, est une observation qui se situe à une distance inhabituelle des autres observations dans un ensemble de données.

```{r}
#afficher boxplot pour chaque questions

library(outliers)

for (i in (1:50)) {
  boxplot(QPE4PL[i], main = colnames(QPE4PL)[i] , outline = TRUE)
}

shapiro.test(QPE4PL$Q3)
boxplot(QPE4PL$Q3)
qqplot <- ggplot(data.frame(sample = QPE4PL$Q3), aes(sample = sample)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Q-Q Plot pour QPE4PL$Q3",
       x = "Quantiles théoriques",
       y = "Quantiles des échantillons") +
  theme_minimal()


# Effectuer le test de Grubbs pour chaque colonne
colonnes_a_tester <- paste0("Q", 1:50)
library(outliers)
# Boucle pour effectuer le test de Grubbs pour chaque colonne
for (colonne in colonnes_a_tester) {
  test_resultat <- rosnerTest(QPE4PL[[colonne]])
  print(paste("Test de Grubbs pour la colonne", colonne, ":"))
  print(test_resultat)
}
library(fpc)
library(EnvStats)
rosnerTest(QPE4PL$Q1)
db <- dbscan(matrix(na.omit(QPE4PL$Q3)), eps = 0.5, MinPts = 4)

# Identification des outliers
outliers <- which(db$cluster == 0)

```


# Analyse descriptive

```{r}

library(psych)
describe(QPE4PLlesson)
describe(QPE4PLimpact)
describe(QPE4PL)
```
```{r}
summary(QPE4PLlesson)
summary(QPE4PLimpact)
library(FactoMineR)

N <- nrow(QPE4PLlesson)
indices <- seq(1, N)

# Indices pairs et impairs
indices_EFAl <- indices[indices %% 2 == 0]
indices_CFAl <- indices[indices %% 2 != 0]

# Diviser le jeu de données en utilisant ces indices
QPE4Ll_EFA <- QPE4PLlesson[indices_EFAl, ]
QPE4Ll_CFA <- QPE4PLlesson[indices_CFAl, ]



indices_CFAl
indices_EFAl
```
```{r}
#Factoshiny(t(QPE4PLlesson))  #si on compile ca ramene à une page où l'on peut faire des ACP, classification ...


```
# Dimensionnalitée

##lesson

```{r}

library(psych)

fa.parallel(QPE4PLlesson, fa="fa", fm="pa") #4

corrless = cor(QPE4PLlesson, use="pairwise.complete.obs")


valeurs_propres =eigen(corrless)$values
valeurs_propres
#Méthode coude
lessonct <- na.omit(as.data.frame(scale(QPE4PLlesson))) #données centré réduite
QPE4PLl_EFA_cor <- cor(lessonct, use = "pairwise.complete.obs")
vp = eigen(QPE4PLl_EFA_cor)$values
scree(QPE4PLl_EFA_cor, factors = FALSE)

scree_data <- data.frame(
  Facteur = 1:length(vp),
  Valeur_Propre = vp
)
print(KMO(QPE4PL_EFAcor))

#donnée centré réduite
ttcr=na.omit(as.data.frame(scale(QPE4PL)))
QPE4PL_EFAcor <- cor(QPE4PL,  use = "pairwise", method = "spearman")
cortest.bartlett(QPE4PL_EFAcor)



ggplot(scree_data, aes(x = Facteur, y = Valeur_Propre)) +
  geom_point() +
  geom_line() +
  geom_text(aes(label = round(Valeur_Propre, 2)), vjust = -0.5, hjust = 0.5) + 
  labs(x = "Nombre de facteurs", y = "Valeurs Propres", title = "Scree Plot") +
  scale_x_continuous(limits = c(1,10 )) +  # Ajustez les limites de l'axe x selon vos besoins
  theme_minimal()

#Méthode Kaiser

vp #Kaiser indique 5, on regarde valeur propre > 1 sur les données centrées réduites

```
## Impact
```{r}
fa.parallel(QPE4PLimpact, fa="fa", fm="pa") #5
corrimp = cor(QPE4PLimpact, use="pairwise.complete.obs")

valeurs_propres =eigen(corrimp)$values
valeurs_propres
library(FactoMineR)
PCA(QPE4PLlessoncr)
PCA(impct)
library(factoextra)
# Charger et nettoyer les données
QPE4PLimpactcr <- na.omit(as.data.frame(scale(na.omit(QPE4PLimpact))))

# Effectuer l'analyse en composantes principales (PCA)
res_pca <- PCA(QPE4PLimpactcr, graph = FALSE)  # Assurez-vous de régler graph = FALSE pour éviter les graphiques redondants

# Visualiser le cercle de corrélation
fviz_pca_var(res_pca, col.var = "black")


# Charger et nettoyer les données
QPE4PLlessoncr <- na.omit(as.data.frame(scale(na.omit(QPE4PLlesson))))

# Effectuer l'analyse en composantes principales (PCA)
res_pca <- PCA(QPE4PLlessoncr, graph = FALSE)  # Assurez-vous de régler graph = FALSE pour éviter les graphiques redondants

# Visualiser le cercle de corrélation
fviz_pca_var(res_pca, col.var = "black")


impct <- na.omit(as.data.frame(scale(na.omit(QPE4PLimpact)))) #données centré réduite
QPE4PLi_EFA_cor <- cor(impct, use = "pairwise.complete.obs")
vp = eigen(QPE4PLi_EFA_cor)$values
#Méthode 1

scree(QPE4PLi_EFA_cor, factors = FALSE)
scree_data <- data.frame(
  Facteur = 1:length(vp),
  Valeur_Propre = vp
)


ggplot(scree_data, aes(x = Facteur, y = Valeur_Propre)) +
  geom_point() +
  geom_line() +
  geom_text(aes(label = round(Valeur_Propre, 2)), vjust = -0.5, hjust = 0.5) + 
  labs(x = "Nombre de facteurs", y = "Valeurs Propres", title = "Scree Plot") +
  scale_x_continuous(limits = c(1,10 )) +  # Ajustez les limites de l'axe x selon vos besoins
  theme_minimal()

#Méthode Kaiser

vp #Kaiser indique 6, on regarde valeur propre > 1 sur les données centrées réduites
```

Dans les données lesson il y a le bon nombre de dimension ce qui est satisfaisant mais pour la partie impact il y en a 6 ou 5

# EFA lesson

```{r}
library(psych)
lowerCor(QPE4PLlesson)
corr.test(QPE4PL,use = "pairwise.complete.obs")$p
corr.test(QPE4PL)$ci
psych::alpha(x=na.omit(QPE4PL))
QPE4PL


splitHalf(QPE4PL)

```

Le mieux est un alpha plus grand que 0.7, ce qui est le cas.

Je vais faire deux parties pour faire l'étude

```{r}


N <- nrow(QPE4PLlesson)
indices <- seq(1, N)

# Indices pairs et impairs
indices_EFAl <- indices[indices %% 2 == 0]
indices_CFAl <- indices[indices %% 2 != 0]

# Diviser le jeu de données en utilisant ces indices
QPE4Ll_EFA <- QPE4PLlesson[indices_EFAl, ]
QPE4Ll_CFA <- QPE4PLlesson[indices_CFAl, ]

# Supprimer les valeurs manquantes
QPE4Ll_EFA <- na.omit(QPE4Ll_EFA)
QPE4Ll_CFA <- na.omit(QPE4Ll_CFA)

indices_CFAl
indices_EFAl


```
 




On va comparer les modèles 
```{r}
QPE4Ll_EFA_cor <- cor(QPE4Ll_EFA, use = "pairwise.complete.obs")
# Then use that correlation matrix to create the scree plot
scree(QPE4Ll_EFA_cor, factors = FALSE)
```
Toujours 5 facteurs avec données coupé c'est bien

Je vais quand même comparer avec 4 facteurs car le trait est très proche de la 5eme valeurs propre

```{r}


EFA_modelth <- fa(QPE4Ll_EFA, nfactors = 5)

QP2 = QPE4Ll_EFA %>% select(-Q14, -Q15)
fa(QP2, nfactors = 5)$loadings

# View results from the model object

EFA_modelth$loadings #14, 22
```

The total n.obs was  193  with Likelihood Chi Square =  193.34  with prob <  0.0073 

Tucker Lewis Index of factoring reliability =  0.947
RMSEA index =  0.04  and the 90 % confidence intervals are  0.022 0.055
BIC =  -585.54

C'est donc un très très bon modèle

```{r}


fa(QPE4Ll_EFA, nfactors = 3)$BIC
fa(QPE4Ll_EFA, nfactors = 4)$BIC
fa(QPE4Ll_EFA, nfactors = 5)$BIC
fa(QPE4Ll_EFA, nfactors = 6)$BIC

```
En fait moins on choisi de facteur est mieux sera le BIC voila pourquoi il faut aussi regardé les critère du TLI, RMSEA ... pour faire le juste milieu entre ce qui est conceptuel et empirique.

```{r}
cor(EFA_modelth$loadings)
```
Ca permet de voir à quel point une question est corrélé à un facteur
```{r}
fa.diagram(EFA_modelth)
fa.diagram(fa(QPE4Ll_EFA, nfactors = 6))
```

# EFA impact

```{r}
library(psych)
lowerCor(QPE4PLimpact)
corr.test(QPE4PLimpact)$p 
corr.test(QPE4PLimpact)$ci
psych::alpha(x=QPE4PLimpact)

```

Je vais faire deux partie pour faire l'étude

```{r}
QPE4PLimpact= na.omit(QPE4PLimpact)

N <- nrow(QPE4PLimpact)
indices <- seq(1, N)
indices_EFA <- indices[indices %% 2 == 0]  # Sélection des indices pairs
indices_CFA <- indices[indices %% 2 != 0]  # Sélection des indices impairs
# Utilisation de ces indices pour diviser le jeu de données en moitiés pour votre EFA et CFA
QPE4Li_EFA <- QPE4PLimpact[indices_EFA, ]
QPE4Li_CFA <- QPE4PLimpact[indices_CFA, ]


```


On va comparer les modèles 
```{r}
QPE4Li_EFA_corcr <- cor(scale(QPE4Li_EFA), use = "pairwise.complete.obs")
# Then use that correlation matrix to create the scree plot
QPE4Li_EFA_cor <- cor((QPE4Li_EFA), use = "pairwise.complete.obs")
scree(QPE4Li_EFA_cor, factors = FALSE)
scree(QPE4Li_EFA_corcr, factors = FALSE)
```
Toujours 6 facteurs avec données coupé dommage

Je vais quand même comparer avec 4 et 5 facteurs

```{r}


EFA_modelvp <- fa(QPE4Li_EFA, nfactors = 6)
# View results from the model object
EFA_modelvp
```

 
The total n.obs was  193  with Likelihood Chi Square =  267.99  with prob <  0.0018 

Tucker Lewis Index of factoring reliability =  0.945
RMSEA index =  0.04  and the 90 % confidence intervals are  0.026 0.053
BIC =  -805.6

Tout est bien


```{r}
fa(QPE4Li_EFA, nfactors = 5)
```
The total n.obs was  193  with Likelihood Chi Square =  324.66  with prob <  1.8e-05 

Tucker Lewis Index of factoring reliability =  0.924
RMSEA index =  0.047  and the 90 % confidence intervals are  0.036 0.059
BIC =  -864.71

Même si le bic est inférieur on voit que le modèle n'est pas aussi bien


```{r}

EFA_model2 =fa(QPE4PLimpact, nfactors = 4)


fa(QPE4PLimpact, nfactors = 4)$loadings
fa(QPE4Li_EFA, nfactors = 4)$loadings
library(tidyverse)
QPi2 = QPE4Li_EFA %>% select(-Q27,-Q30,-Q39,-Q40)
fa(QPi2, nfactors = 4)$loadings


#Q27, 30, 39, 40
EFA_model2$BIC
EFA_model2$loadings    
EFA_model2$communality

fa(QPE4PLimpact, nfactors = 4)$BIC
fa(QPE4Li_EFA, nfactors = 5)$BIC
fa(QPE4Li_EFA, nfactors = 6)$BIC




```
The total n.obs was  193  with Likelihood Chi Square =  455.1  with prob <  3e-14 

Tucker Lewis Index of factoring reliability =  0.857
RMSEA index =  0.065  and the 90 % confidence intervals are  0.056 0.075
BIC =  -855.31

En conclusion le modèle à 4 facteur est le moins bien mais reste correct, peut être qu'il faut enlever des question pour que 4 facteurs soit bien ?



```{r}
fa.diagram(fa(QPE4Li_EFA, nfactors = 4))

fa.diagram(fa(QPE4Li_EFA, nfactors = 5))
```
Néanmoins une chose positive c'est que le modèle proposé correspond assez fortement au modèle théorique


## Analyse confirmatoire lesson avec sem





```{r}
EFA_syn1 <- structure.sem(EFA_modelth)
EFA_syn1
theory_syn_eq1 <- "
APP: Q1, Q2, Q3, Q4  #Apprentissage
GES:Q5,  Q6, Q7, Q8, Q9 #Gestionclasse
CLI: Q10, Q11, Q12, Q13,Q14 #Climatclasse
ACM:  Q15, Q16, Q17, Q18, Q19 #Acticognmot
ACR: Q20, Q21, Q22, Q23 #Acticoref
"
theory_syn1 <- sem::cfa(text = theory_syn_eq1, reference.indicators = FALSE)
# attention package sem et pas lavaan


theory_CFA1 = sem::sem(theory_syn1, data = QPE4Ll_CFA)
summary(theory_CFA1)
options(fit.indices = c("CFI","GFI","RMSEA","BIC"))
sem::modIndices(theory_CFA1, sort = T)
```
C'est souvent significatif le test du chi2 car il y a bcp de donnée
Model Chisquare =  655.9903   Df =  220 Pr(>Chisq) = 6.280688e-45
 Goodness-of-fit index =  0.768102
 RMSEA index =  0.101596   90% CI: (NA, NA)
 Bentler CFI =  0.713193
 BIC =  -501.8016
 
```{r}
summary(theory_CFA1)$BIC

sem::sem(EFA_syn1, data = QPE4Ll_CFA)
EFA_CFA1 = sem:::sem.semmod(EFA_syn1, data = QPE4Ll_CFA)
summary(EFA_CFA1)



EFA_CFA1
```

```{r}
EFA_modelth$loadings
summary(EFA_CFA1)$coeff
```
```{r}
EFA_scores1 <- EFA_modelth$scores

CFA_scores1 <- sem::fscores(EFA_CFA1, data = QPE4Ll_CFA)

plot(density(EFA_scores1[,1], na.rm = TRUE),
xlim = c(-3, 3), ylim = c(0, 1), col = "blue")
lines(density(CFA_scores1[,1], na.rm = TRUE),
xlim = c(-3, 3), ylim = c(0, 1), col = "red")

```

```{r}
#travaile sur theorie_CFA1 car BIC plus petit

sem::modIndices(theory_CFA1, sort = T)
```
C'est assez intéressant car on peut comparer les recommandation de changements par le package sem et lavaan

## Analyse confirmatoire impact avec sem

```{r}
EFA_syn2 = structure.sem(EFA_model2)


theory_syn_eq2 <- "
PHY: Q24, Q25, Q26, Q27 #Physique
PSY: Q28, Q29, Q30, Q31, Q32, Q33, Q34, Q35 #Psychologique
SOC: Q36, Q37, Q38, Q39, Q40, Q41, Q42, Q43, Q44, Q45 #Sociale
COG: Q46, Q47, Q48, Q49, Q50 #Cognitive
"

theory_syn_eq2

theory_syn2 = sem::cfa(text = theory_syn_eq2, reference.indicators = FALSE)


```

```{r}
theory_CFA2 = sem::sem(theory_syn2, data= QPE4Li_CFA)

summary(theory_CFA2)$BIC
EFA_CFA2 = sem::sem(EFA_syn2, data = QPE4Li_CFA)
summary(EFA_CFA2)$BIC

summary(theory_CFA2)

```
Le premier modèle est le meilleur car le BIC est plus petit
```{r}
summary(theory_CFA2)
```
Model Chisquare =  762.7571   Df =  318 Pr(>Chisq) = 1.537118e-38
 Goodness-of-fit index =  0.7607151
 RMSEA index =  0.08534877   90% CI: (NA, NA)
 Bentler CFI =  0.7983109
 BIC =  -910.7783
 
 Modèle moyen
 
 
```{r}
EFA_sc = EFA_model2$scores
CFA_sc = sem::fscores(EFA_CFA2, data = QPE4Li_CFA)
plot(density(EFA_sc[,1], na.rm = TRUE),
xlim = c(-3, 3), ylim = c(0, 1), col = "blue")
lines(density(CFA_sc[,1], na.rm = TRUE),
xlim = c(-3, 3), ylim = c(0, 1), col = "red")
```

## Analyse Confirmatoire lesson avec sem(lavaan)
```{r}
library(semPlot)
library(lavaan)

modellesson <- " 
    APP =~ Q1 + Q2 + Q3 + Q4
    ENS =~ Q6 + Q7 + Q8 + Q9
    CLIM =~ Q10 + Q11 + Q12 + Q13 
    COMO =~   Q16 + Q17 + Q18 + Q19
    CORE =~ Q20 + Q21 + Q22 + Q23 
"

fitlesson <- cfa(model = modellesson, data = QPE4PLlesson)
semPaths(fitlesson, "est", "std", layout = "tree", whatLabels = "est.std", style = "lisrel")
summary(fitlesson, standardized = TRUE, fit.measures= TRUE, rsquare = TRUE)
modindices(fitlesson, sort = TRUE)
fitMeasures(fitlesson, c("rmsea", "srmr", "cfi", "tli"))
```
 
 
```{r}
library(lavaan)
library(semPlot)
modellesson <- " 
    APP =~ Q1 + Q2 + Q3 + Q4
    ENS =~ Q6 + Q7 + Q8 + Q9
    CLIM =~ Q10 + Q11 + Q12 + Q13 
    COMO =~ Q15 + Q16 + Q17 + Q18 + Q19
    CORE =~ Q20 + Q21 + Q22 + Q23 
"

fitlesson <- cfa(model = modellesson, data = QPE4PLlesson)
semPaths(fitlesson, "est", "std", layout = "tree", whatLabels = "est.std", style = "lisrel")
summary(fitlesson, standardized = TRUE, fit.measures= TRUE, rsquare = TRUE)
modindices(fitlesson, sort = TRUE)
fitMeasures(fitlesson, c("rmsea", "srmr", "cfi", "tli"))

#On enlève Q14 et Q15 et Q5 car trop corrélé à d'autre questions

modellesson2 <- '
    F1 =~ Q1 + Q2 + Q3 + Q4
    F2 =~  Q6 + Q7 + Q8 + Q9
    F3 =~ Q10 + Q11 + Q12 + Q13 
    F4 =~  Q16 + Q17 + Q18 + Q19
    F5 =~ Q20 + Q21 + Q22 + Q23 '

fitlesson2 <- cfa(model = modellesson2, data = QPE4PLlesson)
fitMeasures(fitlesson2, c("rmsea", "srmr", "cfi", "tli"))
summary(fitlesson2, standardized = TRUE, fit.measures= TRUE, rsquare = TRUE)
modindices(fitlesson2, sort = TRUE)

#On enleve Q13

modellesson3 <- '
    F1 =~ Q1 + Q2 + Q3 + Q4
    F2 =~  Q6 + Q7 + Q8 + Q9
    F3 =~ Q10 + Q11 + Q12  
    F4 =~  Q16 + Q17 + Q18 + Q19
    F5 =~ Q20 + Q21 + Q22 + Q23 '

fitlesson3 <- cfa(model = modellesson3, data = QPE4PLlesson)
summary(fitlesson3, standardized = TRUE, fit.measures= TRUE, rsquare = TRUE)
modindices(fitlesson3, sort = TRUE)


modellesson4 <- '
    F1 =~ Q1 + Q2 + Q3 + Q4
    F2 =~  Q6 + Q7 + Q8 + Q9
    F3 =~ Q10 + Q11 + Q12  
    F4 =~  Q16 + Q17 + Q18 + Q19
    F5 =~ Q20 + Q21  + Q23 '

fitlesson4 <- cfa(model = modellesson4, data = QPE4PLlesson)
summary(fitlesson4, standardized = TRUE, fit.measures= TRUE, rsquare = TRUE)
modindices(fitlesson4, sort = TRUE)

fitMeasures(fitlesson, c("rmsea", "srmr", "cfi", "tli"))
fitMeasures(fitlesson4, c("rmsea", "srmr", "cfi", "tli"))


anova(fitlesson,fitlesson4)

library(semPlot)
#semPaths(fitlesson, "std", what = "path")
```

Interpréter les charges factorielles
Dans la sortie de summary, recherchez les charges factorielles standardisées (indiquées comme std.lv). Une charge factorielle représente la corrélation entre une variable observée et la variable latente.

Critères d'interprétation :
Charge factorielle élevée (souvent > 0.5) : Indique une forte corrélation entre la variable observée et le facteur latent.
Charge factorielle moyenne (environ entre 0.3 et 0.5) : Indique une corrélation modérée.
Charge factorielle faible (< 0.3) : Indique une faible corrélation.
Charge factorielle proche de 0 : Indique que la variable observée n'est pas bien représentée par le facteur latent.


```{r}

```
```{r}

```




```{r}
RSLT=sem(model=modellesson,data=QPE4PLlesson)
parameterEstimates(RSLT)# : estimations
standardizedSolution(RSLT) #: standardisés
inspect( RSLT, "cor.lv") #: corrélations entre latentes
resid(RSLT, type="standardized") #: résidus standardisés
fitMeasures(RSLT) #: indicateurs de fit
predict(RSLT) #: scores des latentes

```
```{r}
library(MVN)
par(mar=c(1,1,1,1))

library(MVN)

# Effectuer le test de normalité multivariée avec test univarié basé sur Shapiro-Wilk et visualiser des histogrammes
mvn(QPE4PL, subset = NULL, mvnTest = "mardia", univariateTest = "SW")




```

 Modèle correct
 
```{r}
modificationindices(fitlesson, sort = TRUE)
```
Ca permet d'afficher dans l'ordre ce qu'on peut modifier pour avoir un meilleur modèle. Le mieux est de le faire en discutant pour pas que je prenne des décisions nulle.

## AFC impact

```{r}
model2 <- '
PHY =~ Q24 + Q25+ Q26+Q27 #Physique
PSY=~ Q28+ Q29+ Q31+ Q32+ Q33+ Q34+ Q35 #Psychologique
SOC=~ Q36+ Q37+ Q38+ Q41 +Q42+ Q43+ Q44+ Q45 #Sociale
COG=~ Q46+ Q47+ Q48+ Q49+ Q50 #Cognitive '
library(lavaan)
fit <- cfa(model2, data = QPE4PLimpact)
library(semPlot)
semPaths(fit, "std", layout = "tree", whatLabels = "std", edge.label.cex = 0.8, sizeMan = 5, sizeLat = 7)
# Résumé des résultats
summary(fit, fit.measures = TRUE, standardized = TRUE)
# Obtenir les indices de modification
modindices(fit, sort = TRUE, minimum.value = 10)

fitMeasures(fit, c("rmsea", "srmr", "cfi", "tli","BIC"))

#enlever Q29 car trop corrélé avec d'autre questions

model3 <- '
PHY =~ Q24 + Q25+ Q26+Q27 #Physique
PSY=~ Q28+ Q31+ Q32+ Q33+ Q34+ Q35 #Psychologique
SOC=~ Q36+ Q37+ Q38+ Q41 +Q42+ Q43+ Q44+ Q45 #Sociale
COG=~ Q46+ Q47+ Q48+ Q49+ Q50 #Cognitive '



fit2 <- cfa(model3, data = QPE4PLimpact)
fitMeasures(fit, c("rmsea", "srmr", "cfi", "tli","BIC"))
fitMeasures(fit2, c("rmsea", "srmr", "cfi", "tli","BIC"))
anova(fit,fit2)
summary(fit2, fit.measures = TRUE, standardized = TRUE)
modindices(fit2, sort = TRUE, minimum.value = 10)

#On enlève Q29 car trop correlé avec d'autre questions

model4 <- "
PHY =~ Q24 + Q25+ Q26+ Q27 #Physique
PSY=~ Q28+   Q30+ Q31+ Q32+ Q33+ Q34+ Q35 #Psychologique
SOC=~  Q36+ Q38+ Q39+ Q40+ Q41 +Q42+ Q43+ Q44+ Q45 #Sociale
COG=~  Q46 +Q47+ Q48+ Q49+ Q50 #Cognitive"

fit3 <- cfa(model4, data = QPE4PLimpact)
summary(fit3, fit.measures = TRUE, standardized = TRUE)
modindices(fit3, sort = TRUE, minimum.value = 10)

fitMeasures(fit2, c("rmsea", "srmr", "cfi", "tli"))
fitMeasures(fit, c("rmsea", "srmr", "cfi", "tli","BIC"))
fitMeasures(fit2, c("rmsea", "srmr", "cfi", "tli","BIC"))
fitMeasures(fit3, c("rmsea", "srmr", "cfi", "tli","BIC"))

#On s'arrete là

anova(fit2, fit)


```
```{r}
fitMeasures(fit2, c("rmsea", "srmr", "cfi", "tli"))
```


## Analyse sem pour impact

```{r}
model2 <- "
PHY =~ Q24 + Q25+ Q26+ Q27 #Physique
PSY=~ Q28+ Q29+ Q30+ Q31+ Q32+ Q33+ Q34+ Q35 #Psychologique
SOC=~ Q36+ Q37+ Q38+ Q39+ Q40+ Q41 +Q42+ Q43+ Q44+ Q45 #Sociale
COG=~ Q46+ Q47+ Q48+ Q49+ Q50 #Cognitive
PHY ~~ PSY
PSY~~ SOC
SOC~~COG
COG~~PHY
"

EFA_model2$loadings

library(lavaan)
model.fit = cfa(model= model2, data = QPE4PLimpact)

summary(model.fit, standardized = TRUE,
fit.measures = TRUE)
```
Modèle vraiment pas horrible même si critère pas respecté

```{r}
modificationindices(model.fit, sort = TRUE)
```
```{r}
sem::modIndices(theory_CFA2, sort = T)
```
```{r}
model2t <- "
PHY =~ Q24 + Q25+ Q26+ Q27+ Q35 #Physique
PSY=~ Q28+ Q29+ Q30+ Q31+ Q32+ Q33+ Q34 + Q40 #Psychologique
SOC=~ Q36+ Q37+ Q38+ Q39+ Q41 +Q42+ Q43+ Q44+ Q45 #Sociale
COG=~ Q46+ Q47+ Q48+ Q49+ Q50 #Cognitive
PHY ~~ PSY
PSY~~ SOC
SOC~~COG
COG~~PHY
"


modelt.fit = cfa(model= model2t, data = QPE4PLimpact)


anova(model.fit,modelt.fit)

fitmeasures(model.fit, c("aic", "ecvi") )
fitmeasures(modelt.fit, c("aic", "ecvi") )


```
On regarde les valeur de l'AIC et le BIC le plus bas pour faire le choix du meilleur modèle
 